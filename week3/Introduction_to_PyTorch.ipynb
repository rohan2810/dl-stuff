{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjYDWVa3V4Tu"
      },
      "source": [
        "# **Module 3: Introduction to PyTorch**\n",
        "\n",
        "## Introduction\n",
        "[Pytorch](https://pytorch.org/) is an optimized tensor library for deep learning using GPUs and CPUs. Tensors are a specialized data structure that are very similar to arrays and matrices. Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. The ability to leverage GPUs for model training provides faster and more efficient computations than what CPUs provide. Additionally, tensors have some incredible powerful gradient calculation built in which greatly simplifies your code.\n",
        "\n",
        "In this notebook we will give a brief introduction to using Pytorch and tensors to better prepare us for using them for Deep Learning in subsequent notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors"
      ],
      "metadata": {
        "id": "9fm9PcH9l7OF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S982Co0hU4KB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor created directly from a list. The data type is automatically inferred."
      ],
      "metadata": {
        "id": "gKoQrkIRibH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "tensor_data = torch.tensor(data)\n",
        "print(tensor_data)"
      ],
      "metadata": {
        "id": "0JoFxDrziLft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58420b2e-5f20-495c-97c8-40faa9628d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor created from a NumPy array."
      ],
      "metadata": {
        "id": "O-fcEJo8ijwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "tensor_np = torch.from_numpy(np_array)\n",
        "print(tensor_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RAmdH0eirEH",
        "outputId": "b81ce15d-cce9-4b5d-88bf-bab48d22123e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "New tensors can be created from other tensors. The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden."
      ],
      "metadata": {
        "id": "TQaEudgTjVmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_zeros = torch.zeros_like(tensor_data) # retains the properties of tensor_data\n",
        "print(f\"Zeros Tensor: \\n {x_zeros} \\n\")\n",
        "\n",
        "x_ones = torch.ones_like(tensor_data) # retains the properties of tensor_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(tensor_data, dtype=torch.float) # overrides the datatype of tensor_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bv283h9jYM7",
        "outputId": "bc8f528c-3897-4bf7-a07a-a62fe2eb586b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zeros Tensor: \n",
            " tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.0183, 0.1118, 0.6546],\n",
            "        [0.6724, 0.2216, 0.5212],\n",
            "        [0.1774, 0.8555, 0.4546]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor can also be created from random or constant values.\n",
        "In the functions below, we pass in a tuple, shape, which specifies the dimension of the output tensor."
      ],
      "metadata": {
        "id": "853MH6qKkxLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (3, 2,)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "rand_tensor = torch.rand(shape)\n",
        "\n",
        "\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sz-BFYyj2Ud",
        "outputId": "57671664-88c6-4cbd-db1d-0a185d05b540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zeros Tensor: \n",
            " tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "Ones Tensor: \n",
            " tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.5821, 0.2798],\n",
            "        [0.9201, 0.2044],\n",
            "        [0.2085, 0.9706]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Along with displaying the values of the tensor like we have above, we can print out additional attributes of the tensor which will be helpful for using it. We've seen the concepts of *shape* and *datatype* in previous notebooks, and now we will introduce a new concept known as *device*. ***Device*** in this context specifies where calculations are run. Typically, CPUs (central processing unit) are used by default as it's essentially the brain of any computing device, carrying out the instructions of a program by performing control, logical, and input/output (I/O) operations. GPUs (graphical processing unit) have smaller-sized but many more logical cores (arithmetic logic units or ALUs, control units and memory cache) whose basic design is to process a set of simpler and more identical computations in parallel.   "
      ],
      "metadata": {
        "id": "XI0wuEkemCDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of tensor: {rand_tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {rand_tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {rand_tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4J_bftel_9O",
        "outputId": "8ba2c346-3cd2-4013-afe7-08e1325f58fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 2])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPUs usually perform machine learning tasks quicker and more efficiently than CPUs, so we prefer using them whenever we're able to.\n",
        "Nvidia created a parallel computing architecture and platform for its GPUs called CUDA, which gave developers access and the ability to express simple processing operations in parallel through code. The rand_tensor is currently stored on CPU. If you’re using Colab, allocate a GPU by going to Edit > Notebook Settings. The below code will switch the device used from CPU to GPU if available."
      ],
      "metadata": {
        "id": "JG664MUWnX6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  tensor = rand_tensor.to('cuda')\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVKzN3GIjMdL",
        "outputId": "d6d2d080-3393-46a3-c1ce-96e4a601e24e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradients\n",
        "\n",
        "The below example is pulled from: https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html\n",
        "\n",
        "When training neural networks, the most frequently used algorithm is back propagation. In this algorithm, parameters (model weights) are adjusted according to the gradient of the loss function with respect to the given parameter.\n",
        "\n",
        "To compute those gradients, PyTorch has a built-in differentiation engine called torch.autograd. It supports automatic computation of gradient for any computational graph.\n",
        "\n",
        "Consider the simplest one-layer neural network, with input x, parameters w and b, and some loss function. It can be defined in PyTorch in the following manner:"
      ],
      "metadata": {
        "id": "-JdJLa7OmH09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(5)  # input tensor\n",
        "y = torch.zeros(3)  # expected output\n",
        "w = torch.randn(5, 3, requires_grad=True)\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "z = torch.matmul(x, w)+b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
        "\n",
        "print(\"loss:\", loss)"
      ],
      "metadata": {
        "id": "nWhRW_LBtin5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b127522-c706-465c-8a69-203213b3ee24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: tensor(1.3639, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function that we apply to tensors to construct computational graph is in fact an object of class Function. This object knows how to compute the function in the forward direction, and also how to compute its derivative during the backward propagation step. A reference to the backward propagation function is stored in grad_fn property of a tensor. You can find more information of Function in the documentation."
      ],
      "metadata": {
        "id": "F79eOVbzwVmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Gradient function for z = {z.grad_fn}\")\n",
        "print(f\"Gradient function for loss = {loss.grad_fn}\")"
      ],
      "metadata": {
        "id": "1YFcXNXowQY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc0a17c-e61a-40cf-c19c-69e9e2ea2da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient function for z = <AddBackward0 object at 0x7fce1d583890>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7fce19b04a90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To optimize weights of parameters in the neural network, we need to compute the derivatives of our loss function with respect to parameters, namely, we need $\\frac{\\partial loss}{\\partial w}$\n",
        "  and $\\frac{\\partial loss}{\\partial b}$\n",
        "  under some fixed values of x and y. To compute those derivatives, we call loss.backward(), and then retrieve the values from w.grad and b.grad:"
      ],
      "metadata": {
        "id": "_b_XyUptwZmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "id": "rRTeQITrwbgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13584e1-ab8d-4801-c475-af97765de879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0081, 0.3072, 0.0330],\n",
            "        [0.0081, 0.3072, 0.0330],\n",
            "        [0.0081, 0.3072, 0.0330],\n",
            "        [0.0081, 0.3072, 0.0330],\n",
            "        [0.0081, 0.3072, 0.0330]])\n",
            "tensor([0.0081, 0.3072, 0.0330])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization\n",
        "\n",
        "By using the auto-differentiation powers of PyTorch, we can easily perform the optimization tasks necessary for training large neural networks. In the code snippet below, we plot a function and its corresponding derivative to visualize this.\n",
        "\n",
        "Our goal in deep learning is to minimize our loss function, and by looking at this simple plot we can see how the derivative can inform us of the minimum value of a given function.\n",
        "\n",
        "*Note the use of .detach.numpy() to get a value back from the tensor and device, into a numpy array, for plotting."
      ],
      "metadata": {
        "id": "BpW79qRkmeK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the derivative of the function with multiple values\n",
        "x = torch.linspace(-20, 20, 20, requires_grad = True)\n",
        "Y = 5*x ** 2\n",
        "y = torch.sum(Y)\n",
        "y.backward()\n",
        "\n",
        "# ploting the function and derivative\n",
        "function_line, = plt.plot(x.detach().numpy(), Y.detach().numpy(), label = 'Function')\n",
        "function_line.set_color(\"red\")\n",
        "derivative_line, = plt.plot(x.detach().numpy(), x.grad.detach().numpy(), label = 'Derivative')\n",
        "derivative_line.set_color(\"green\")\n",
        "plt.xlabel('x')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "nu0uilzUy3nM",
        "outputId": "03e6bffb-5e75-4c6b-e7ef-3ea7abe03120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Looking Ahead\n",
        "\n",
        "As we have seen, tensors can be extremely powerful and can greatly simplify the implementation of our programs. We will build on this auto-gradient framework and apply it to more complex neural networks in the following modules. If you would like more information on Tensors and Pytorch as a whole, make sure to check out their tutorial and docs which can be found [here](https://pytorch.org/tutorials/beginner/basics/intro.html)."
      ],
      "metadata": {
        "id": "doTU0oTMLQhp"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}